{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Basic_Image_manipulation.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPOC/NVR0LwDfSdpR9Wb2LX"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zKSdkHsA_Wv_"},"source":["# Live Tutorial 1a - Basic Image manipulation in a Python interactive notebook.\n","\n","----------\n","## Qbio Summer School 2021\n","--------------\n","\n","```\n","Instructor: Luis U. Aguilera\n","Author: Luis U. Aguilera\n","Contact Info: luis.aguilera@colostate.edu\n","\n","Copyright (c) 2021 Dr. Brian Munsky. \n","Dr. Luis Aguilera, Will Raymond\n","Colorado State University.\n","Licensed under MIT License.\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"XLhGsyu8hgIP"},"source":["<img src= https://github.com/MunskyGroup/uqbio2021/raw/main/module_0/presentation/images/Slide1.png alt=\"drawing\" width=\"1200\"/>\n"]},{"cell_type":"markdown","metadata":{"id":"YmGRxtCzqWqs"},"source":["# Abstract \n","\n","This notebook provides a list of procedures to analyze microscope images. The notebook describes what a scientific image is. How to extract relevant information from the image. At the end of the tutorial, the student is expected to acquire the computational skills to implement the following list of objectives independently.\n","\n","## List of objectives\n","\n","\n","1. To load the python modules commonly used to work with microscopy data.\n","2. To understand what is a computational image.\n","3. To understand what is a monochromatic image and a color image.\n","4. To select and slice the dimensions in a sequence of microscope images.\n","5. To apply differents filters to remove noise from the image.\n","6. To perform basic mathematic operations, including rotation, translation, and scaling. \n"]},{"cell_type":"markdown","metadata":{"id":"MabWJ6vkA5Dh"},"source":["# Working with images in python"]},{"cell_type":"markdown","metadata":{"id":"_XltNqo0PlDt"},"source":["The following lines of code import and install some libraries. For more information, look at the library name on the  Python Package Index [(PyPI)](https://pypi.org/)."]},{"cell_type":"code","metadata":{"id":"oUp21jU285ef"},"source":["# Loading libraries\n","import matplotlib.pyplot as plt # Library used for plotting\n","from matplotlib.patches import Rectangle # module to plot a rectangle in the image\n","import urllib.request # importing library to download data\n","import numpy as np # library for array manipulation\n","import seaborn as sn # plotring library\n","import pandas as pd # data frames library\n","import tifffile # library to store numpy arrays in TIFF\n","import pathlib; from pathlib import Path # library to work with file paths"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIo5kSPETm6v"},"source":["# Installing and updating libraries\n","%%capture\n","!pip uninstall scikit-image -y\n","!pip install -U scikit-image\n","!pip install wget \n","import skimage # Library for image manipulation\n","from skimage.io import imread # sublibrary from skimage\n","import wget # importing library to download data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ms-rgCqfiyPE"},"source":["<img src= https://github.com/MunskyGroup/uqbio2021/raw/main/module_0/presentation/images/Slide3.png alt=\"drawing\" width=\"1200\"/>"]},{"cell_type":"markdown","metadata":{"id":"9rw73zKSSzxS"},"source":["## Downloading, opening and visualizing images \n","\n"]},{"cell_type":"code","metadata":{"id":"CryOMGJyTJKW"},"source":["# Downloading the image from figshare SupFig1c_BG_MAX_Cell04.tif\n","urls = ['https://ndownloader.figshare.com/files/26751209','https://ndownloader.figshare.com/files/26751203','https://ndownloader.figshare.com/files/26751212','https://ndownloader.figshare.com/files/26751218']\n","print('Downloading file...')\n","urllib.request.urlretrieve(urls[1], './image_cell.tif') # "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9iaLiiUZ_l9"},"source":["# importing the image as variable img\n","figName = './image_cell.tif'\n","img = imread(figName) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dw1h-pNreUMt"},"source":["## Understanding digital images."]},{"cell_type":"markdown","metadata":{"id":"EbpGVc5afAH9"},"source":["What is a digital image?"]},{"cell_type":"code","metadata":{"id":"9UZmW3AXaQpg"},"source":["# what is img?\n","print('image type =', type(img))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r7RLPW07e9_8"},"source":["\n","What is the shape of the image?\n","\n"]},{"cell_type":"code","metadata":{"id":"FhXrbP-6e7dk"},"source":["print('image shape =',img.shape )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HFw7CDHXfJsM"},"source":["Displaying a section of the image. Notice that an image is only a matrix of numbers."]},{"cell_type":"code","metadata":{"id":"x-1E5Y8Iv0Hs"},"source":["df = pd.DataFrame(img[0,250:260,250:260,0] ) # converting the image into a pandas data frame\n","# Plotting\n","fig, ax = plt.subplots(1,2, figsize=(25, 10))\n","ax[0].imshow(img[0,:,:,0],cmap='gray') \n","ax[0].add_patch(Rectangle(xy=(250, 250),width=10,height=10,linewidth=3,color='yellow',fill=False)) # rectangle in the image\n","# Plotting the heatmap of a section in the image\n","sn.heatmap(df, annot=True,cmap=\"gray\",fmt='d', ax=ax[1])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZzeF30uxxCcO"},"source":["plt.figure(figsize=(7,7))\n","plt.imshow(img[0,:,:,0],cmap='gray') # Notice that only a timepoint and a color is plotted.\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QPiYgZz3gSZG"},"source":["From the [image's publication](https://www.biorxiv.org/content/10.1101/2020.04.03.024414v2) we can obtain the metadata. Indicating that the following information:\n","\n","Dimension  | Meaning |  Value\n","---------|---------- |----------\n","0   | Time        | 35 (frames)\n","1   | Y-dimension | 512 pixels\n","2   | X-dimension | 512 pixels\n","3   | Color       | 3 color image (R,G,B)\n"]},{"cell_type":"markdown","metadata":{"id":"sMOU60u5k5Lq"},"source":["<img src= https://github.com/MunskyGroup/uqbio2021/raw/main/module_0/presentation/images/Slide5.png alt=\"drawing\" width=\"1200\"/>"]},{"cell_type":"markdown","metadata":{"id":"Y_yUuV207STB"},"source":["Intensity values in the image"]},{"cell_type":"code","metadata":{"id":"1ph7AsyjgYVj"},"source":["# minimum and maximum intensity values on the image\n","max_intensity_value = np.amax(img)\n","min_intensity_value = np.amin(img)\n","\n","print('Maximum intensity : ', max_intensity_value)\n","print('Minimum intensity : ', min_intensity_value)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u2HVf-6R7WPz"},"source":["Intensity distribution in the image"]},{"cell_type":"code","metadata":{"id":"PN5SazcD7c52"},"source":["# plotting the intensity distribution for a specific timepoint and an specific channel\n","plt.figure(figsize=(7,7))\n","plt.hist(img[0,:,:,0].flatten(), bins=80,color='orangered')\n","plt.xlabel('Value')\n","plt.ylabel('Frequency')\n","plt.title('Intnesity Histogram')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qOGE49vGg51F"},"source":["Summary of image properties: \n","\n","* 4 dimensional tensor [T,Y,X,C]. \n","* Numpy array\n","* Intensity range (0, 6380)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ESGFKhs-echL"},"source":["\n","### Grayscale images"]},{"cell_type":"code","metadata":{"id":"BVwyTqU-dny1"},"source":["# please try to run the following line of code and find why it doesn't work?\n","#plt.imshow(img) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ff6g-sRFZxF1"},"source":["# Visualzing a monochromatic image\n","plt.figure(figsize=(7,7))\n","plt.imshow(img[0,:,:,0],cmap='gray') # Notice that only a timepoint and a color is plotted.\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JRvxNhRHcNdc"},"source":["# Visualzing a monochromatic image with a different colormap\n","plt.figure(figsize=(7,7))\n","plt.imshow(img[0,:,:,0],cmap= 'BrBG')  # colormap options are: 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean',\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aUpbCqxnNgXe"},"source":["### Bit depth, intensity in images."]},{"cell_type":"markdown","metadata":{"id":"WSMC6pqVhmJd"},"source":["Bit depth is the information stored on each pixel in the image. \n","\n","Bits  | Color values: $2^n$\n","---------|------------------\n","1 bit    | 2 \n","8 bit    | 256 \n","12 bit   | 4096\n","16 bit   | 65536\n","\n"]},{"cell_type":"code","metadata":{"id":"RR-DZx0HpJDv"},"source":["# https://stackoverflow.com/questions/46689428/convert-np-array-of-type-float64-to-type-uint8-scaling-values/46689933\n","def convert(img, target_type_min, target_type_max, target_type):\n","    '''\n","    This function is inteded to normalize img and change the image to the specified target_type\n","      img: numpy array\n","      target_type_min: int\n","      target_type_max: int\n","      target_type: str, optins are: np.uint\n","    '''\n","    imin = img.min()\n","    imax = img.max()\n","    a = (target_type_max - target_type_min) / (imax - imin)\n","    b = target_type_max - a * imax\n","    new_img = (a * img + b).astype(target_type)\n","    return new_img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xdsuzjVaN2Px"},"source":["Check this [link](https://numpy.org/doc/stable/user/basics.types.html) for a complete list of numpy data types."]},{"cell_type":"code","metadata":{"id":"SHAqS4BZhlOx"},"source":["# Normalizing and converting images between different bit-depts.\n","#Convert an image to unsigned byte format, with values in [0, 1].\n","img_int1 = convert(img, 0,1,target_type=np.bool_)\n","#Convert an image to unsigned byte format, with values in [0, 8].\n","img_int3 = convert(img, 0,8,target_type=np.uint8)\n","#Convert an image to unsigned byte format, with values in [0, 255].\n","img_int8 = convert(img, 0,255,target_type=np.uint8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zY6HplbNnxTw"},"source":["print('Range in 1-bit image: [', np.amin(img_int1),',' ,np.amax(img_int1) , ']' )\n","print('Range in 3-bit image: [', np.amin(img_int3),',' ,np.amax(img_int3) , ']' )\n","print('Range in 8-bit image: [', np.amin(img_int8),',' ,np.amax(img_int8) , ']' )\n","print('Range in 16-bit image: [', np.amin(img),',' ,np.amax(img) , ']' )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_aPRFIXkqXu"},"source":["# Side-by-side comparison\n","fig, ax = plt.subplots(1,3, figsize=(30, 20))\n","ax[0].imshow(img_int3[0,:,:,0],cmap='gray')\n","ax[0].set(title='3bit')\n","ax[1].imshow(img_int8[0,:,:,0],cmap='gray')\n","ax[1].set(title='8bit')\n","ax[2].imshow(img[0,:,:,0],cmap='gray')\n","ax[2].set(title='16bit')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PY5IHAFiEKDp"},"source":["#### Values in the image"]},{"cell_type":"code","metadata":{"id":"xfxVTg3qEKRU"},"source":["# Selecting a section of the images and converting this section into a data frame\n","min_selection_area = 300\n","max_selection_area = min_selection_area+10\n","df_3bit = pd.DataFrame(img_int3[0,min_selection_area:max_selection_area,min_selection_area:max_selection_area,0] ) # Range in 3-bit image: [ 0 , 8 ]\n","df_8bit = pd.DataFrame(img_int8[0,min_selection_area:max_selection_area,min_selection_area:max_selection_area,0] ) # Range in 8-bit image: [ 0 , 255 ]\n","df_16bit = pd.DataFrame(img[0,min_selection_area:max_selection_area,min_selection_area:max_selection_area,0] ) # Range in 16-bit image: [ 0 , 65536 ]. In this particular image the original maximum value is 6380\n","\n","# Plotting\n","fig, ax = plt.subplots(1,3, figsize=(30, 7))\n","# Plotting the heatmap of a section in the image\n","sn.heatmap(df_3bit, annot=True,cmap=\"gray\",fmt='d', ax=ax[0])\n","ax[0].set_title('3-bit image')\n","sn.heatmap(df_8bit, annot=True,cmap=\"gray\",fmt='d', ax=ax[1])\n","ax[1].set_title('8-bit image')\n","sn.heatmap(df_16bit, annot=True,cmap=\"gray\",fmt='d', ax=ax[2])\n","ax[2].set_title('16-bit image')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ar0uiRhfOlGT"},"source":["#### File size for different data types and bit depth"]},{"cell_type":"code","metadata":{"id":"KwSKSyPYINNa"},"source":["#saving the images to disk\n","tifffile.imwrite('temp_img_int8.tif', img_int8)\n","tifffile.imwrite('temp_img_int16.tif', img)\n","\n","# Loading the images \n","print(\"File size of the 8-bit image in Mb is: \", round(Path('temp_img_int8.tif').stat().st_size/1e6))\n","print(\"File size of the 16-bit image in Mb is: \", round(Path('temp_img_int16.tif').stat().st_size/1e6))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o0mGFJ8dM8zl"},"source":["### Color images. Color channel [R,G,B]."]},{"cell_type":"code","metadata":{"id":"IwLLE5sB0fUX"},"source":["# Visualzing a color image\n","plt.figure(figsize=(10,10))\n","plt.imshow(img_int8[0,:,:,:]) # Notice that only a timepoint and all colors are plotted.\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uf1706KGOOv3"},"source":["### Working with images in Python"]},{"cell_type":"markdown","metadata":{"id":"MjUK0rpoOW6K"},"source":["### Basic image manipulation"]},{"cell_type":"markdown","metadata":{"id":"it4IFSnMOqFp"},"source":["#### Slicing"]},{"cell_type":"markdown","metadata":{"id":"-x_xa1Ow4kW1"},"source":["In this section we select parts of the image.\n","\n","The image is a numpy array with dimensions:\n","```\n","image [time, y-axis, x-axis, colors]\n","```\n","\n","If we need to select the following elements:\n","* timepoint(frame) 5\n","* y-axis from 100 to 200 pixel\n","* x-axis from 230 to 300 pixel\n","* \"Green\" color (Color 1 in the standard format [R,G,B]),\n","\n","The way to slice the numpy array is as follows:\n","\n","```\n","image[5, 100:200, 230:300, 1]\n","```\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"FkxEwsc54BYp"},"source":["# Ploting a subsection of the image.\n","# Time point: 0\n","# Y-range: [100:300]\n","# X-range: [100:300]\n","# Channel: Red (0)\n","plt.figure(figsize=(7,7))\n","plt.imshow(img_int8[0,100:300,100:300,0],cmap='gray') # Notice that only a timepoint and a color is plotted.\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RRwow-M54eHs"},"source":["# Ploting a subsection of the image.\n","# Time point: 22\n","# Y-range: [230:300]\n","# X-range: [155:350]\n","# Channel: Blue (2)\n","plt.figure(figsize=(7,7))\n","plt.imshow(img_int8[22,23:300,155:350,2],cmap='gray') # Notice that only a timepoint and a color is plotted.\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wqf1CPcqOv_x"},"source":["#### Thresholding"]},{"cell_type":"code","metadata":{"id":"3i09YvCR692X"},"source":["# Making values less than the average equal to zero.\n","\n","img_copy = img.copy() # making a copy of our img\n","img_section = img_copy[0,:,:,0] # selecting a timepoint and color channel\n","#img_section[img_section>1000]=1000  # thresholding image values larger than 1000 equal to 1000.\n","img_section[img_section>np.mean(img_section)]=np.mean(img_section)  # thresholding image values larger than the mean equal to the mean.\n","\n","# Plotting\n","plt.figure(figsize=(7,7))\n","plt.imshow(img_section,cmap='gray') # Notice that only a timepoint and a color is plotted.\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xmfGuqIbOlwY"},"source":["#### Filters"]},{"cell_type":"markdown","metadata":{"id":"JuLkk8wFLJvD"},"source":["[Filters](https://ai.stanford.edu/~syyeung/cvweb/tutorial1.html) are used to :\n","\n","*   Noise reduction\n","*   Edge detection\n","*   Sharpening\n","*   Blurring\n","\n","The mathematical operation is a 2D convolution. This convolution involves defining a smaller kernel matrix and applying the same mathematical operation to each pixel in the entire image. A more complete explanation can be found in this [video](https://youtu.be/8rrHTtUzyZA?t=72).\n"]},{"cell_type":"markdown","metadata":{"id":"2gbyFSTKkig2"},"source":["<img src= https://github.com/MunskyGroup/uqbio2021/raw/main/module_0/presentation/images/Slide6.png alt=\"drawing\" width=\"1200\"/>"]},{"cell_type":"markdown","metadata":{"id":"xoq0pDWRgago"},"source":["##### Gaussian Filter. Noise reduction and blurring."]},{"cell_type":"markdown","metadata":{"id":"mqPRfQwVgfNX"},"source":["$G_\\sigma = \\frac{1}{2\\pi\\sigma^2}e{\\frac{x^2+y^2}{2\\sigma^2}}$"]},{"cell_type":"code","metadata":{"id":"ol0Hsh3RhCRn"},"source":["# Section that creates the Gaussian Kernel Matrix\n","def gaussian_kernel (size_matrix,sigma):\n","  '''\n","  This function returns a normalized gaussian kernel matrix\n","  size_matrix : int\n","  sigma: float\n","  '''\n","  ax = np.linspace(-(size_matrix - 1) / 2., (size_matrix - 1) / 2., size_matrix)\n","  xx, yy = np.meshgrid(ax, ax)\n","  kernel = np.exp(-0.5 * (np.square(xx) + np.square(yy)) / np.square(sigma)) \n","  kernel = kernel/kernel.sum() # normalizing to the sum\n","  return kernel\n","\n","# Gaussian Kernel matrix for different sigmas.\n","kernel_gaussian_sigma_3 = gaussian_kernel (size_matrix=20,sigma=3)\n","kernel_gaussian_sigma_5 = gaussian_kernel (size_matrix=20,sigma=5)\n","kernel_gaussian_sigma_10 = gaussian_kernel (size_matrix=20,sigma=10)\n","\n","# Side-by-side comparizon\n","fig, ax = plt.subplots(1,3, figsize=(20, 10))\n","ax[0].imshow(kernel_gaussian_sigma_3,cmap='gray')\n","ax[0].set(title='Gaussian kernel $\\sigma$ =3')\n","ax[1].imshow(kernel_gaussian_sigma_5,cmap='gray')\n","ax[1].set(title='Gaussian kernel $\\sigma$ =5')\n","ax[2].imshow(kernel_gaussian_sigma_10,cmap='gray')\n","ax[2].set(title='Gaussian kernel $\\sigma$ =10')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MSNOiAivMRgj"},"source":["Example using [gaussian filter scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html). For a complete  list of filters in scipy use the following [link](https://docs.scipy.org/doc/scipy/reference/ndimage.html)"]},{"cell_type":"code","metadata":{"id":"wCvsao4vLWN9"},"source":["# Imoporting the library with the filter modules\n","from scipy.ndimage import gaussian_filter\n","\n","img_copy = img.copy() # making a copy of our img\n","img_section = img_copy[0,:,:,0] # selecting a timepoint and color channel\n","\n","# Applying the filter\n","img_gaussian_filter_simga_1 = gaussian_filter(img_section, sigma=1)\n","img_gaussian_filter_simga_10 = gaussian_filter(img_section, sigma=10)\n","\n","# Side-by-side comparizon\n","fig, ax = plt.subplots(1,3, figsize=(30, 10))\n","ax[0].imshow(img_section,cmap='gray')\n","ax[0].set(title='Original')\n","\n","# noise reduction \n","ax[1].imshow(img_gaussian_filter_simga_1,cmap='gray')\n","ax[1].set(title='Gaussian Filter $\\sigma$ =1 Noise reduction')\n","\n","# Blurring\n","ax[2].imshow(img_gaussian_filter_simga_10,cmap='gray')\n","ax[2].set(title='Gaussian Filter $\\sigma$ =10 Image Blurring')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qt7m9Z77NDK9"},"source":["Filters in scikit-image. [Difference of gaussians](https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.difference_of_gaussians).\n","\n","This filter is used to locate elements between a low and a high value.\n","\n"," For a complete list of filters in scikit-image use the following [link](https://scikit-image.org/docs/stable/api/skimage.filters.html)."]},{"cell_type":"code","metadata":{"id":"RmrdlxfqN4vf"},"source":["# Importing skiimage filters module\n","from skimage.filters import difference_of_gaussians\n","\n","img_copy = img.copy() # making a copy of our img\n","img_section = img_copy[0,:,:,0] # selecting a timepoint and color channel\n","\n","# Applying the filter to our image\n","img_diff_gaussians = difference_of_gaussians(img_section,low_sigma=1, high_sigma=10)\n","#img_diff_gaussians = difference_of_gaussians(img_section,low_sigma=5, high_sigma=10)\n","\n","# Side-by-side comparizon\n","fig, ax = plt.subplots(1,2, figsize=(20, 10))\n","ax[0].imshow(img_section,cmap='gray')\n","ax[0].set(title='Original')\n","ax[1].imshow(img_diff_gaussians,cmap='gray')\n","ax[1].set(title='Difference of gaussians')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xu1xikL-O3iP"},"source":["#### Rotation"]},{"cell_type":"markdown","metadata":{"id":"Xfuu0S9lXd__"},"source":["Simple rotation can be achieved by array manipulation."]},{"cell_type":"markdown","metadata":{"id":"eWG-CiIrXpDh"},"source":["Rotate an image 90$^\\circ$ use transpose property of the array. [transpose](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.T.html)"]},{"cell_type":"code","metadata":{"id":"G___ihkhYfcE"},"source":["img_copy = img.copy() # making a copy of our img\n","img_section = img_copy[0,:,:,0] # selecting a timepoint and color channel\n","\n","transposed_img = img_section.T # transposed property in a numpy array\n","\n","# Side-by-side comparizon\n","fig, ax = plt.subplots(1,2, figsize=(20, 10))\n","ax[0].imshow(img_section,cmap='gray')\n","ax[0].set(title='Original')\n","ax[1].imshow(transposed_img,cmap='gray')\n","ax[1].set(title= 'Image rotated by 90 degrees' )\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aV3x-0XvWdgR"},"source":["\n","Library [Rotate scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.rotate.html#scipy.ndimage.rotate)"]},{"cell_type":"code","metadata":{"id":"bYkFWx7_LUc2"},"source":["# Importing skiimage rotation module\n","from scipy import ndimage as nd\n","\n","img_copy = img.copy() # making a copy of our img\n","img_section = img_copy[0,:,:,0] # selecting a timepoint and color channel\n","\n","# rotate image to a given angle\n","selected_angle = 90\n","img_rotation = nd.rotate(img_section, angle=selected_angle)\n","\n","# Side-by-side comparizon\n","fig, ax = plt.subplots(1,2, figsize=(20, 10))\n","ax[0].imshow(img_section,cmap='gray')\n","ax[0].set(title='Original')\n","ax[1].imshow(img_rotation,cmap='gray')\n","ax[1].set(title= 'Image rotated by '+str(selected_angle)+ ' degrees' )\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dVqFESd_PFNk"},"source":["#### Image transformation. "]},{"cell_type":"markdown","metadata":{"id":"2I99VaYAJ5pE"},"source":["Consist of applying rotation, scaling, and translation processes to the image."]},{"cell_type":"markdown","metadata":{"id":"i-dok6uhYYp-"},"source":["List of available [transformations in skimage](https://scikit-image.org/docs/stable/auto_examples/transform/plot_transform_types.html). Blog with more information about [applying transformations to images](https://towardsdatascience.com/image-processing-with-python-applying-homography-for-image-warping-84cd87d2108f)"]},{"cell_type":"code","metadata":{"id":"df60Z4LwYeen"},"source":["# Importing skiimage transformation module\n","from skimage import transform\n","\n","img_copy = img.copy() # making a copy of our img\n","img_section = img_copy[0,:,:,0] # selecting a timepoint and color channel\n","\n","#  transformation matrix\n","tform = transform.SimilarityTransform(\n","    scale = 0.95,                  # float, scaling value\n","    rotation = np.pi/90,          # Rotation angle in counter-clockwise direction as radians. pi/180 rad = 1 degrees\n","    translation=(100, 1))     # (x, y) values for translation .\n","print('Transformation matrix : \\n', tform.params , '\\n')\n","\n","# Applying the transformation\n","tf_img = transform.warp(img_section, tform.inverse)\n","\n","# Side-by-side comparizon\n","fig, ax = plt.subplots(1,2, figsize=(20, 10))\n","ax[0].imshow(img_section,cmap='gray')\n","ax[0].set(title='Original')\n","ax[1].imshow(tf_img,cmap='gray')\n","ax[1].set_title('transformation')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ff6-FeqUA9he"},"source":["## Working with a sequence of images"]},{"cell_type":"markdown","metadata":{"id":"jZfytq3ss_vI"},"source":["### Video"]},{"cell_type":"markdown","metadata":{"id":"HH-l14hgGlgv"},"source":["Visualizing a video with [ipywidgets](https://ipywidgets.readthedocs.io/en/latest/)"]},{"cell_type":"code","metadata":{"id":"7InIfB-_TOWU"},"source":["import ipywidgets as widgets # Importing library\n","from ipywidgets import interact, interactive, HBox, Layout, VBox #  importing modules and functions.\n","\n","# Figure size\n","plt.rcParams[\"figure.figsize\"] = (10,10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fhBwdHtHRCHJ"},"source":["def video_viewer( drop_channel, time):\n","    '''\n","    This function is intended to display an image from an array of images (specifically, video: img_int8). img_int8 is a numpy array with dimension [T,Y,X,C].\n","    drop_channel : str with options 'Ch_0', 'Ch_1', 'Ch_2', 'All'\n","    time: int with range 0 to the number of frames in video.\n","    '''\n","    plt.figure(1)\n","    if drop_channel == 'Ch_0':\n","      temp_image = img_int8[time,:,:,0]\n","      plt.imshow(temp_image,cmap='gray')\n","    elif drop_channel == 'Ch_1':\n","      temp_image = img_int8[time,:,:,1]\n","      plt.imshow(temp_image,cmap='gray')\n","    elif drop_channel == 'Ch_2':\n","      temp_image = img_int8[time,:,:,2]\n","      plt.imshow(temp_image,cmap='gray')\n","    else:\n","      temp_image = img_int8[time,:,:,:]    \n","      plt.imshow(temp_image)\n","    plt.show()\n","\n","# Defining an interactive plot\n","interactive_plot = interactive(video_viewer,\n","                               drop_channel = widgets.Dropdown(options=['Ch_0', 'Ch_1', 'Ch_2', 'All'],description='Channel',value='Ch_1'),  # drop to select the channel\n","                               time = widgets.IntSlider(min=0,max=img_int8.shape[0]-1,step=1,value=0,description='Time'))       # time slider parameters\n","# Creates the controls\n","controls = HBox(interactive_plot.children[:-1], layout = Layout(flex_flow='row wrap'))\n","# Creates the outputs\n","output = interactive_plot.children[-1]\n","\n","# Display the controls and output as an interactive widget\n","display(VBox([controls, output]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UJJ1bUOpqH-M"},"source":["### Images with 3-dimensional space, Fluorescence in situ hybridization (FISH) images."]},{"cell_type":"code","metadata":{"id":"rZf1xgAxqORF"},"source":["# Downloading the image to Colab\n","%%capture\n","drive = pathlib.Path(\"/content\")\n","found_files = list(drive.glob('**/FISH_example.zip'))\n","if len(found_files) != 0:\n","  print(f\"File already downloaded and can be found in {found_files[0]}.\")\n","else:\n","  !wget --no-check-certificate 'https://www.dropbox.com/s/i9mz2b3qminj4wh/FISH_example.zip?dl=0' -r -A 'uc*' -e robots=off -nd -O 'FISH_example.zip'\n","  !unzip FISH_example.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2jIyWYmFtfdE"},"source":["# importing the image as variable img\n","figName_FISH = './FISH_example.tif'\n","img_FISH = imread(figName_FISH) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tXtyYPupsvuO"},"source":["# this image has dimension [Z,Y,X]\n","print(img_FISH.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8d5oSuDxjRS"},"source":["max_val = np.percentile(img_FISH, 99)\n","img_FISH [img_FISH> max_val] = max_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TCxd_Fm1tsfK"},"source":["# Plotting the FISH image\n","fig, ax = plt.subplots(1,img_FISH.shape[0], figsize=(30, 10))\n","for i in range (0,img_FISH.shape[0]):\n","  ax[i].imshow(img_FISH[i,:,:],cmap='gray')\n","  #ax[i].set(title= ['Z=',str(i)])\n","  ax[i].axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vGuMhGoPyu0I"},"source":["Moving in and out of focus"]},{"cell_type":"code","metadata":{"id":"PjAK5e47yHaP"},"source":["def FISH_viewer( z_value):\n","    '''\n","    This function is intended to display an image from an array of images (specifically, video: img_int8). img_int8 is a numpy array with dimension [T,Y,X,C].\n","    drop_channel : str with options 'Ch_0', 'Ch_1', 'Ch_2', 'All'\n","    time: int with range 0 to the number of frames in video.\n","    '''\n","    plt.figure(1)\n","    temp_FISH_image = img_FISH[z_value,:,:]    \n","    plt.imshow(temp_FISH_image,cmap='gray')\n","    plt.show()\n","\n","# Defining an interactive plot\n","interactive_plot = interactive(FISH_viewer,\n","                               z_value = widgets.IntSlider(min=0,max=img_FISH.shape[0]-1,step=1,value=0,description='z-value'))       # time slider parameters\n","# Creates the controls\n","controls = HBox(interactive_plot.children[:-1], layout = Layout(flex_flow='row wrap'))\n","# Creates the outputs\n","output = interactive_plot.children[-1]\n","\n","# Display the controls and output as an interactive widget\n","display(VBox([controls, output]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_FLGKKdKmR_T"},"source":["## Operations on multiple images"]},{"cell_type":"markdown","metadata":{"id":"wYkIt7-Okq9U"},"source":["<img src= https://github.com/MunskyGroup/uqbio2021/raw/main/module_0/presentation/images/Slide7.png alt=\"drawing\" width=\"1200\"/>"]},{"cell_type":"markdown","metadata":{"id":"kVOEK4mKzCul"},"source":["Maximum projections"]},{"cell_type":"code","metadata":{"id":"aq7o2XFay0bC"},"source":["# Making a copy of our sequence of images\n","img_FISH_copy = img_FISH.copy() # making a copy of our img\n","\n","# applying a maximum projection\n","img_max_z_projection = np.max(img_FISH, axis=0)\n","\n","# Plotting\n","plt.figure(figsize=(7,7))\n","plt.imshow(img_max_z_projection,cmap='gray')\n","plt.axis('off')\n","plt.show()\n","\n","# Printing results\n","print('Dimensions on the original sequence of images :', img_FISH.shape, '\\n')\n","print('Dimensions on the maximum projection :', img_max_z_projection.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3LKgKz3UdL1c"},"source":["Normalizing intensity for every channel and time point."]},{"cell_type":"code","metadata":{"id":"X873jFGndLCK"},"source":["img_normalized = np.zeros_like(img)   # prealocating memory\n","number_timepoints, y_dim, x_dim, number_channels = img.shape[0], img.shape[1], img.shape[2], img.shape[3] # obtaining the dimensions size\n","\n","# Normalization using a nested for-loop\n","for index_channels in range (number_channels): # iteration for every channel\n","    for index_time in range (number_timepoints): # iterating for every time point\n","        max_val = np.amax(img[index_time,:,:,index_channels])\n","        min_val = np.amin(img[index_time,:,:,index_channels])\n","        img_normalized[index_time,:,:,index_channels] = (img[index_time,:,:,index_channels]-min_val) / (max_val-min_val) # normalization \n","\n","# Printing the output\n","print('Range velues in the original sequence of images: (' , np.amin(img) ,',', np.amax(img) ,')\\n' )\n","print('Range velues in the normalized sequence of images: (' , np.amin(img_normalized) ,',', np.amax(img_normalized) ,')\\n' )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oh_Ubv6ARPFM"},"source":["Transposing dimensions"]},{"cell_type":"code","metadata":{"id":"vpN1ZaXqRRcp"},"source":["# Making a copy of our sequence of images\n","img_int8_copy = img_int8.copy() # making a copy of our img\n","\n","# reshaping the video. Changing the Time position (0) to the last place (3).\n","img_transposed = np.transpose(img_int8_copy, (3, 1, 2, 0))\n","\n","# Printing results\n","print('Dimensions on the original sequence of images :', img_int8_copy.shape, '\\n')\n","print('Dimensions on the maximum projection :', img_transposed.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2dMLxd-wu2zh"},"source":["# Short test"]},{"cell_type":"markdown","metadata":{"id":"11KpYp5Gu5YV"},"source":["Please answer the following [test](https://docs.google.com/forms/d/e/1FAIpQLSdyAuiq2lID3XWgYcdLQbBzLVMwhdd6GMSBSPy9fW_NdZmq_Q/viewform?usp=sf_link)"]},{"cell_type":"markdown","metadata":{"id":"UFBJIdmvbTKM"},"source":["# References"]},{"cell_type":"markdown","metadata":{"id":"_SzkyFx2bYPG"},"source":["\n","> Image downloaded from https://figshare.com from publication: \"Forero-Quintero, L.S., Raymond, W., Handa, T. et al. Live-cell imaging reveals the spatiotemporal organization of endogenous RNA polymerase II phosphorylation at a single gene. Nat Commun 12, 3158 (2021). https://doi.org/10.1038/s41467-021-23417-0\"\n",">\n"]}]}